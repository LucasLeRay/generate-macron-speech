{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "sagemaker = boto3.client('runtime.sagemaker')\n",
    "\n",
    "with open('macron.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(text)\n",
    "max_id = len(tokenizer.word_index)\n",
    "\n",
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = .2 Mes chers compatriotes, c'est que c'est une règle de réduire les règles de ce qu'on a besoin de votre région de ce que je pense que c'est dur. je puis pas d'ailleurs d\n",
      "t = .5 Mes chers comparations, parce que c'est une des régions pour que c'est privé pour se pour soi même d'ailleurs de région aux gens nos mois qui sont aussi, c'est une\n",
      "t = 1 Mes chers comportements donc ces règles, toutes là vous avez prendre, c'est que je puis être pressaire, trois jours qu'on a bien aussi pour y avoir des donner du m\n",
      "t = 2 Mes chers compoenerient freinedoyoe'mes, éconongerdier,. non? y, un jeune, en domjey vo, vous psocée. voilà,., et ùid'. à règlements ni d'aptal. notre fermer. les \n"
     ]
    }
   ],
   "source": [
    "def next_char(body, temperature=1):\n",
    "    X_new = preprocess([body])\n",
    "    result = sagemaker.invoke_endpoint(\n",
    "        EndpointName='tensorflow-inference-2021-05-26-13-22-36-181',\n",
    "        ContentType='application/json',\n",
    "        Body = json.dumps(X_new.numpy().tolist())\n",
    "    )\n",
    "    y_proba = result['Body'].read().decode()\n",
    "    y_proba = json.loads(y_proba)['predictions']\n",
    "    y_proba = np.array(y_proba)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "def complete_text(body, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        body += next_char(body, temperature)\n",
    "    return body\n",
    "\n",
    "print('t = .2', complete_text('Mes chers compatri', 150, .2))\n",
    "print('t = .5', complete_text('Mes chers compatri', 150, .5))\n",
    "print('t = 1', complete_text('Mes chers compatri', 150, 1))\n",
    "print('t = 2', complete_text('Mes chers compatri', 150, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
