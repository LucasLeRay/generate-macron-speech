{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "sagemaker = boto3.client('runtime.sagemaker')\n",
    "\n",
    "with open('macron.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(text)\n",
    "max_id = len(tokenizer.word_index)\n",
    "\n",
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = .2 Mes chers compatriotes, si on va se respecter les règles de la fête, qui ont été partout si on va se respecter les règles de la formation de rester chez eux de nos conc\n",
      "t = .5 Mes chers compatriotes, je remercie de dire des mesures de s'est du monde. il y aura des métropoles parce que c'est dur. c'est dur. il faut que c'est une règle de pas d\n",
      "t = 1 Mes chers compatriotes. qui est ce que qu'il y a ça par jour toutes les jeunes, on e comprennent, piendrons clest-à-dire toutes ces prochaines dont on qui sont avoir mo\n",
      "t = 2 Mes chers compatriotes policiels euh, beauspour partout huit, péenné. encopes, y celony enlenurant tout, cresauceux ça veut rédurs la nappé à,uil est-à-regiquer. on inf\n"
     ]
    }
   ],
   "source": [
    "def next_char(body, temperature=1):\n",
    "    X_new = preprocess([body])\n",
    "    result = sagemaker.invoke_endpoint(\n",
    "        EndpointName='tensorflow-inference-2021-05-26-13-22-36-181',\n",
    "        ContentType='application/json',\n",
    "        Body = json.dumps(X_new.numpy().tolist())\n",
    "    )\n",
    "    y_proba = result['Body'].read().decode()\n",
    "    y_proba = json.loads(y_proba)['predictions']\n",
    "    y_proba = np.array(y_proba)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "def complete_text(body, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        body += next_char(body, temperature)\n",
    "    return body\n",
    "\n",
    "print('t = .2', complete_text('Mes chers compatri', 150, .2))\n",
    "print('t = .5', complete_text('Mes chers compatri', 150, .5))\n",
    "print('t = 1', complete_text('Mes chers compatri', 150, 1))\n",
    "print('t = 2', complete_text('Mes chers compatri', 150, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
